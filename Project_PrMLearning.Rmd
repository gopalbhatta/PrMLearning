---
title: "Project: Practical Machine Learning"
output: html_document
---
##Introduction
Using weight lifting exercise dataset related to accelerometers on the belt, forearm, arm, and dumbell of 6 research study participants, this project focuses on predicting the manner in which the subjects did exercise. Our training data consists of accelerometer data and a label identifying the quality of the activity the participant was doing. Our testing data consists of accelerometer data without the identifying label. Our goal is to predict the labels for the test set observations.

The codes used when creating the model, estimating the out-of-sample error, and making predictions are given below. A brief description of each step of the process was also shown.

####Installing and loading required packages
```{r, echo = TRUE}
setwd("G:/Data Science Course Materials/Practical Machine Learning")
library(knitr)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(e1071)
```

####Loading data
```{r, echo = TRUE}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```
####Setting seed
```{r, echo = TRUE}
set.seed(12345)
```

####Cross validation of the dataset
Cross validation was achieved by splitting the training data into a test set and a training set, 60% for myTraining, 40% for myTesting. The data was partitioned by the classe variable to ensure the training set and test set contain examples of each class. 
```{r, echo = TRUE}
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
```
####Cleaning data
Transformations were done in cleaning the dataset.
1) Cleaning NearZeroVariance Variables (NZV):
```{r, echo = TRUE}
myDataNZV <- nearZeroVar(myTraining, saveMetrics=TRUE)
```
Subset without NonZeroVariance Variables
```{r, echo = TRUE}
myNZVvars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")
myTraining <- myTraining[!myNZVvars]
```
To check the new n observations
```{r, echo = TRUE}
dim(myTraining)
```
2) Killing first column of Dataset - Removing ID variable so that it does not interfer with ML Algorithms:
```{r, echo = TRUE}
myTraining <- myTraining[c(-1)]
```
3) Cleaning Variables with too many NAs. Variables with > 60% of NA's have been omitted since these variables will not provide much power in prediction.
```{r, echo = TRUE}
trainingV3 <- myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) { #for every column in the training dataset
        if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) { #if n of NAs > 60% of total observations
        for(j in 1:length(trainingV3)) {
            if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { #if the columns are the same:
                trainingV3 <- trainingV3[ , -j] #Remove that column
            }   
        } 
    }
}

#To check the new n observations
dim(trainingV3)

#Seting back to our set:
myTraining <- trainingV3
rm(trainingV3)
```

Applying transformations in testing data sets.
```{r, echo = TRUE}
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58]) #already with classe column removed
myTesting <- myTesting[clean1]
testing <- testing[clean2]

#To check the new n observations
dim(myTesting)
```

To ensure proper functioning of Decision Trees and especially RandomForest Algorithm with the Test data set (data set provided), data need to be coerced into the same type:
```{r, echo = TRUE}
for (i in 1:length(testing) ) {
        for(j in 1:length(myTraining)) {
        if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
            class(testing[j]) <- class(myTraining[i])
        }      
    }      
}


testing <- rbind(myTraining[2, -58] , testing) #note row 2 does not mean anything, this shall be removed:
testing <- testing[-1,]
```

####Using ML algorithms for prediction: Decision Tree
```{r, echo = TRUE}
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
```

view the decision tree with fancy
```{r, echo = TRUE}
fancyRpartPlot(modFitA1)
```

Prediction
```{r, echo = TRUE}
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
```

Confusion Matrix to test results:
```{r, echo = TRUE}
confusionMatrix(predictionsA1, myTesting$classe)
```

####Using ML algorithms for prediction: Random Forests
```{r, echo = TRUE}
modFitB1 <- randomForest(classe ~. , data=myTraining)
```

Predicting in-sample error:
```{r, echo = TRUE}
predictionsB1 <- predict(modFitB1, myTesting, type = "class")
```

confusion Matrix to test results:
```{r, echo = TRUE}
confusionMatrix(predictionsB1, myTesting$classe)
```
Random Forests provided better results, as expected.

####Generating Files to submit as answers for the Assignment
For Random Forests we use the following formula, which yielded a much better prediction in in-sample:
```{r, echo = TRUE}
predictionsB2 <- predict(modFitB1, testing, type = "class")
```

###Function to generate files with predictions to submit for assignment
```{r, echo = TRUE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsB2)
```